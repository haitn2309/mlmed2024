\documentclass{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx} % Required for including images
\usepackage[english]{babel}
\usepackage{titlesec}
\title{ECG Classification Report}
\author{BI12-150 Tran Ngoc Hai}
\date{10/3/2024}

\begin{document}

\maketitle{ECG Datasets}

\section{Introduction}

This project focuses on the analysis of electrocardiogram (ECG) signals with the aim of detecting and classifying various cardiac anomalies. ECG signals are crucial for the diagnosis of cardiovascular diseases, as they reflect the electrical activity of the heart. Machine learning models offer a promising avenue for assisting clinicians in interpreting ECG data by automatically recognizing patterns indicative of specific heart conditions.

In the initial phase of the project, we begin by loading the dataset, which comprises ECG signal readings taken from the MIT-BIH Arrhythmia Database. The database is widely used for research in this area and has been annotated by experts to provide a benchmark for assessing the performance of arrhythmia detection algorithms.


\section{Dataset Description}

 Two separate CSV files are loaded: `mitbihtest.csv` and `mitbihtrain.csv`, which contain the test and training data respectively. Each file consists of rows representing individual ECG signal sequences, with each sequence containing 188 data points. These data points correspond to the normalized voltage values of the ECG signal at different time intervals. 

\section{Data Preprocessing}
 
The data preprocessing stage is a crucial step that involves preparing the dataset for subsequent analysis and modeling. This phase ensures that the data fed into the model is clean, formatted correctly, and representative of the problem at hand. The following steps were implemented for data preprocessing:

\begin{enumerate}
    \item \textbf{Data Loading}: The ECG signal dataset was loaded from CSV files into Pandas DataFrames for easy manipulation and analysis. The datasets include several thousand rows of ECG readings, with each row corresponding to a separate heartbeat signal.
    \item \textbf{Exploratory Data Analysis}: To understand the distributions of different features, histograms were plotted for each column in the dataset. This allowed us to visually inspect the range and distribution of values, as well as to detect any anomalies or outliers.
    \item \textbf{Normalization}: The data values were normalized to ensure that the range of the ECG signal readings did not negatively impact the performance of the machine learning algorithms. Normalization is particularly important for neural network models, which are sensitive to the scale of input data.
    \item \textbf{Data Cleaning}: The cleaning step involved handling any missing or corrupt values in the dataset. In this dataset, each signal sequence was complete, and no missing values were detected.
    \item \textbf{Feature Selection}: The columns with non-unique values between 1 and 50 were selected for plotting. The feature selection process helped to identify relevant features that could contribute to accurate predictions.
    \item \textbf{Data Splitting}: The dataset was split into training and testing sets to provide a robust evaluation of the model's performance. A standard practice of an 80-20 split was used, with 80\% of the data used for training and the remaining 20\% reserved for testing.
\end{enumerate}

Histograms for the first few columns of the dataset are shown in Figure \ref{fig:histograms}. These visualizations provide a snapshot of the underlying data distribution, which is pivotal in understanding the patterns the model will learn.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{image1.png} % Ensure the file name doesn't have spaces and is correct
    \caption{Histograms showing the distribution of values in the first few columns of the ECG dataset.}
    \label{fig:histograms}
\end{figure}


The aforementioned preprocessing steps laid a strong foundation for training machine learning models, as they helped to mitigate issues that could arise from poorly scaled or noisy data.

Data preprocessing is a critical step that ensures the quality and the usefulness of the data for machine learning models. The preprocessing phase of the ECG dataset consisted of the following tasks:

\begin{enumerate}
    \item \textbf{Data Cleaning}: We started by removing columns with missing values using the \texttt{df.dropna(axis='columns')} function to ensure the integrity of the dataset. We further filtered the dataset to retain only those columns with more than one unique value, thereby eliminating constant columns that do not provide informative features for the model.
    
    \item \textbf{Feature Selection}: The dataset was then subject to feature selection, which aimed at reducing dimensionality and selecting relevant features for the analysis. This step was necessary to improve model accuracy and reduce computational complexity.
    
    \item \textbf{Correlation Analysis}: To explore the relationships between different features, a correlation matrix was computed. The correlation matrix provides insights into the degree to which variables in the dataset are linearly related. This step is crucial for identifying features that are strongly correlated, which may affect the performance of certain machine learning models due to multicollinearity.
\end{enumerate}
    
\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{image2.png} 
    \caption{Correlation matrix of the features in the ECG dataset. The matrix provides a visual representation of feature interdependencies.}
    \label{fig:correlation_matrix}
\end{figure}

The visualization of the correlation matrix was implemented using Matplotlib and Seaborn libraries, as shown in the code snippet provided. The heatmap depicts the strength of correlation between every pair of features, with a color-coded scheme where yellow represents a high positive correlation and blue represents a low or negative correlation, as depicted in Figure \ref{fig:correlation_matrix}.


These preprocessing steps were essential for preparing the data, enabling the machine learning models to learn from the most relevant features and perform accurately in classifying ECG signals.

Understanding the relationships between features is essential to grasp how each attribute contributes to the target variable. To this end, we visualized the interactions between different features using scatter and density plots. This technique helps to observe the correlation between pairs of features and the distribution of individual features.

We utilized the \texttt{scatter\_matrix} function from the Pandas plotting module, which creates a grid of scatter plots for each pair of features, enabling us to see both the pairwise relationships and individual feature distributions along the diagonal. This method is especially useful for identifying features that have linear relationships, which could suggest a potential for feature reduction or signal the presence of multicollinearity that might warrant further attention.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{image3.png}
    \caption{Scatter and density plots of the ECG dataset features. Diagonal plots show the kernel density estimation, and off-diagonal plots show the scatter plots with the correlation coefficient annotated for each pair.}
    \label{fig:scatter_density}
\end{figure}

The resulting plot, as depicted in Figure \ref{fig:scatter_density}, provides a detailed view of the feature interdependencies. Each subplot outside the diagonal shows a scatter plot for a pair of features, with the Pearson correlation coefficient annotated. The diagonal plots are kernel density estimations that depict the distribution of each feature. High correlation coefficients are indicative of a strong linear relationship, while coefficients closer to zero suggest a lack of linear correlation.

These visualizations form a part of our exploratory data analysis, enabling us to make informed decisions regarding feature engineering and model selection later in the process.

\section{Model Implementation}
For the task of classifying ECG signals into their respective categories, we constructed a neural network model using the TensorFlow and Keras libraries. The model's architecture and training process are outlined below.

\subsection{Model Architecture}
The implemented model is a fully connected feedforward neural network, also known as a Multilayer Perceptron (MLP), consisting of the following layers:

\begin{itemize}
    \item An input layer with a shape corresponding to the number of features in our dataset.
    \item Two hidden layers, each comprising 64 neurons and utilizing the ReLU activation function for non-linear transformations.
    \item An output layer with a number of neurons equal to the unique classes in the target variable, employing the softmax activation function to output probability distributions over the classes.
\end{itemize}

The number of unique classes, denoted as \( n\_classes \), is dynamically determined from the unique values of the training labels.

\subsection{Model Compilation}
The model is compiled with the Adam optimizer, a widely used variation of stochastic gradient descent. For the loss function, we employed sparse categorical crossentropy due to its suitability for multi-class classification tasks where the labels are provided as integers.

\subsection{Training}
We converted our training features and labels into numpy arrays to ensure compatibility with TensorFlow, and then proceeded to train the model for 10 epochs with a validation split of 20\%. This split allows us to monitor the model's performance on a validation set during training, which helps to detect overfitting early on.

\subsection{Evaluation}
Post-training, the model's performance is evaluated on a separate test set to assess its generalization capabilities. The metrics used for evaluation are loss and accuracy, which provide insights into how well the model is performing in terms of error rate and the proportion of correct predictions.

\begin{verbatim}
model.evaluate(X_test, y_test)
\end{verbatim}

The accuracy metric is especially important in medical applications, as it directly relates to the model's diagnostic reliability.

In conclusion, the model implementation phase is crucial for establishing a robust framework for classifying ECG signals. The training and evaluation steps ensure that the model learns effectively and provides trustworthy predictions that could potentially assist in medical diagnosis.

\section{Model Training and Evaluation}

After the implementation and compilation of the neural network model, the training process commenced. The model was trained on the preprocessed dataset for a predefined number of epochs, with a portion of the training data held out for validation purposes. This approach allows us to monitor the model's learning progress and adjust if overfitting is detected.

To visualize the model's training and validation performance over epochs, accuracy and loss metrics were plotted at the end of each epoch. The following code snippet was used to generate the plots, which illustrate how the model's accuracy and loss evolved during the training process:

\begin{verbatim}
import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history['accuracy'], label='Train')
plt.plot(history['val_accuracy'], label='Validation')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history['loss'], label='Train')
plt.plot(history['val_loss'], label='Validation')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.tight_layout()
plt.show()
\end{verbatim}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.48\textwidth]{image4.png}
    \hfill
    \includegraphics[width=0.48\textwidth]{image5.png}
    \caption{Training and validation accuracy (left) and loss (right) of the neural network model over epochs.}
    \label{fig:model_training_evaluation}
\end{figure}

Figure \ref{fig:model_training_evaluation} depicts the resulting plots. As observed, the model demonstrates an increase in accuracy and a decrease in loss over time on the training set. The validation metrics follow a similar trend, indicating that the model is generalizing well to unseen data. This visualization plays a critical role in understanding the learning dynamics and ensuring that the model does not overfit to the training data.


\subsection{Predictions and Model Evaluation}

With the model trained, the next step was to generate predictions on the test data and evaluate the model's performance. The prediction phase for both binary and multiclass classification tasks can be summarized as follows:

\begin{verbatim}
predictions = model.predict(X_test)

# For binary classification
predicted_classes_binary = (predictions > 0.5).astype(int)

# For multiclass classification
predicted_classes_multiclass = np.argmax(predictions, axis=1)
\end{verbatim}

For binary classification problems, the predictions are thresholded at 0.5, converting the model's output probabilities into class labels. In contrast, for multiclass classification, the class with the highest probability is selected as the prediction for each sample.

Post-prediction, the model was subjected to a quantitative evaluation using the test dataset. This evaluation utilized the \texttt{evaluate} function provided by Keras, which returned the loss and accuracy metrics:

\begin{verbatim}
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")
\end{verbatim}

The resulting test accuracy was found to be 1.0, indicating perfect classification performance on the test dataset. However, the test loss was reported as NaN, which could suggest an issue with the evaluation process or data that warrants further investigation. Typically, a loss of NaN indicates that there may be numerical instability, such as an overflow or divide by zero during the computation of the loss function.

Given the perfect accuracy and the unexpected loss value, additional steps such as cross-validation and deeper analysis of the model's predictions might be necessary to ensure the reliability of these results.

\subsection{Performance Metrics}

A comprehensive evaluation of the model was performed using various performance metrics, each offering insight into different aspects of the model's predictive capabilities.

\begin{itemize}
    \item \textbf{Accuracy}: This metric measures the proportion of correct predictions out of all predictions made. An accuracy of 1.0 indicates that the model correctly predicted every instance in the test set, which is an exceptional scenario, often prompting a careful review to rule out data leakage or overfitting.
    
    \item \textbf{Precision}: Precision evaluates the number of true positive predictions against the total number of positive predictions made. In other words, it answers the question, "Of all the instances the model predicted to be positive, how many were actually positive?" A perfect precision score across all classes suggests that the model did not make any false positive predictions, which is particularly important in medical diagnostics where false alarms are undesirable.
    
    \item \textbf{Recall}: Also known as sensitivity, recall measures the ability of the model to detect all actual positives. It is defined as the number of true positives divided by the sum of true positives and false negatives. A recall of 1.0 implies that the model detected all positive instances, and no condition was left undiagnosed.
    
    \item \textbf{F1 Score}: The F1 score is the harmonic mean of precision and recall, providing a single measure that balances both metrics. An F1 score of 1.0 indicates not only high precision but also high recall, which in practice is quite difficult to achieve, especially on imbalanced datasets.
\end{itemize}

\subsection{Confusion Matrix Analysis}

The confusion matrix was employed to provide a detailed breakdown of the model's performance across the different classes. It presents the true class labels against the predicted class labels, allowing for a nuanced analysis of the model's behavior.

In the observed confusion matrix, all instances fall along the diagonal, indicating a perfect classification with no instances being mislabeled. This result is remarkable and typically necessitates additional validation to ensure the model's robustness and to confirm that the training and evaluation were conducted correctly.

In conclusion, while the metrics indicate outstanding performance, they are subject to verification through additional testing methodologies, such as cross-validation, to ensure that the model is truly effective and not subject to underlying biases or dataset-specific idiosyncrasies.


\section{Conclusion}

In this study, we developed a neural network to classify ECG signals from the MIT-BIH Arrhythmia Database. The data was rigorously preprocessed to ensure quality input for the model, which consisted of two hidden layers and a softmax output layer tailored for multiclass classification. Training results were promising, showing significant improvement in accuracy and a decrease in loss over epochs.

However, the model's perfect performance metrics and the resulting confusion matrix indicate flawless classification, which is atypical in real-world datasets and warrants further investigation for potential overfitting or data leakage. These findings underscore the importance of cautious interpretation of results that appear too good to be true.

Future efforts will focus on cross-validation, testing on external datasets, and experimentation with more complex architectures to validate the model's effectiveness. This project underscores the potential of leveraging machine learning for accurate and automated cardiac anomaly detection, which could greatly aid in clinical diagnosis.

\end{document}

