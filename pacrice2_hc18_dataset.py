# -*- coding: utf-8 -*-
"""Pacrice2 HC18 Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/103A1ZCjvaaQNgPMcDQp982LCl0NfD2tX
"""

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

data = pd.read_csv('test_set_pixel_size.csv')
data

from matplotlib import pyplot as plt
data['pixel size(mm)'].plot(kind='hist', bins=20, title='pixel size(mm)')
plt.gca().spines[['top', 'right',]].set_visible(False)

data.head()

# @title pixel size(mm)

from matplotlib import pyplot as plt
data['pixel size(mm)'].plot(kind='line', figsize=(8, 4), title='pixel size(mm)')
plt.gca().spines[['top', 'right']].set_visible(False)

data2 = pd.read_csv('training_set_pixel_size_and_HC.csv')
data2

data2.head()

# @title head circumference (mm)

from matplotlib import pyplot as plt
data2['head circumference (mm)'].plot(kind='hist', bins=20, title='head circumference (mm)')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title pixel size(mm) vs head circumference (mm)

from matplotlib import pyplot as plt
data2.plot(kind='scatter', x='pixel size(mm)', y='head circumference (mm)', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

df = pd.concat([data, data2], axis=0)

df.shape

df.head()

df.info()

df.describe()

from matplotlib import pyplot as plt
_df_14['head circumference (mm)'].plot(kind='line', figsize=(8, 4), title='head circumference (mm)')
plt.gca().spines[['top', 'right']].set_visible(False)

# Histogram for head circumference
df['head circumference (mm)'].hist(bins=50)
plt.xlabel('Head Circumference (mm)')
plt.ylabel('Frequency')
plt.title('Distribution of Head Circumference Measurements')
plt.show()

# For the correlation matrix, ensure only numeric data is considered
correlation_matrix = df.corr(numeric_only=True)
print(correlation_matrix)

# When filling missing values, specify numeric_only=True to silence the warning
df.fillna(df.mean(numeric_only=True), inplace=True)

df.columns

# Correctly reference the column names with the exact spelling and spacing
features = df.drop('head circumference (mm)', axis=1)
target = df['head circumference (mm)']

# Proceed with the train-test split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

print(X_train.dtypes)  # This will show the data type of each column in X_train

# Assuming 'filename' is the column that contains the filenames such as '766_HC.png'
features = df.drop('filename', axis=1)

# Convert all columns to numeric, coercing errors to NaNs (which you'll handle in the next step)
features = features.apply(pd.to_numeric, errors='coerce')

# Fill NaNs with the mean value of each column or another imputation strategy
features.fillna(features.mean(), inplace=True)

X = features.values  # Convert DataFrame to numpy array
y = df['head circumference (mm)'].values  # Assuming this is your target column

# Then split your data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the model
history = model.fit(X_train, y_train, epochs=100, validation_split=0.2, batch_size=32)

from tensorflow.keras import layers, models

def build_model(input_shape):
    model = models.Sequential()
    model.add(layers.Dense(64, activation='relu', input_shape=(input_shape,)))
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(1)) # Output layer for regression

    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

model = build_model(X_train.shape[1])
model.summary()

# This assumes 'filename' is the column with the image filenames.
# Make sure to replace 'filename' with the actual name of the column in your DataFrame.
features = df.drop(['head circumference (mm)', 'filename'], axis=1)

features = features.apply(pd.to_numeric, errors='coerce')  # Convert all columns to numeric, coercing errors to NaNs
features.fillna(features.mean(), inplace=True)  # Fill NaNs with the mean value of each column

test_loss, test_mae = model.evaluate(X_test, y_test)
print(f"Test MSE: {test_loss}")
print(f"Test MAE: {test_mae}")

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Model Loss Over Epochs')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.show()

predictions = model.predict(X_test)

print(history.history['loss'])
print(history.history['val_loss'])

test_mse, test_mae = model.evaluate(X_test, y_test)
print(f'Test MAE: {test_mae}')

